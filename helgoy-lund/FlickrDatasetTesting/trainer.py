from __future__ import print_function

from keras.preprocessing.image import ImageDataGenerator

batch_size = 32
nb_classes = 10
data_augmentation = False
nb_epoch = 1


def train_model(model_to_train, X_train, X_test, Y_train, Y_test):
	X_train = X_train.astype('float32')
	X_test = X_test.astype('float32')
	X_train /= 255
	X_test /= 255
	if not data_augmentation:
		print('Not using data augmentation.')
		model_to_train.fit(X_train, Y_train,
		                   batch_size=batch_size,
		                   nb_epoch=nb_epoch,
		                   validation_data=(X_test, Y_test),
		                   shuffle=True)
	else:
		print('Using real-time data augmentation.')

		# this will do preprocessing and realtime data augmentation
		datagen = ImageDataGenerator(
			featurewise_center=False,  # set input mean to 0 over the dataset
			samplewise_center=False,  # set each sample mean to 0
			featurewise_std_normalization=False,  # divide inputs by std of the dataset
			samplewise_std_normalization=False,  # divide each input by its std
			zca_whitening=False,  # apply ZCA whitening
			rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
			width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
			height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
			horizontal_flip=True,  # randomly flip images
			vertical_flip=False)  # randomly flip images

		# compute quantities required for featurewise normalization
		# (std, mean, and principal components if ZCA whitening is applied)
		datagen.fit(X_train)

		# fit the model on the batches generated by datagen.flow()
		model_to_train.fit_generator(datagen.flow(X_train, Y_train,
		                                          batch_size=batch_size),
		                             samples_per_epoch=X_train.shape[0],
		                             nb_epoch=nb_epoch,
		                             validation_data=(X_test, Y_test))
